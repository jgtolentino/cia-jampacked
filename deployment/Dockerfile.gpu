# JamPacked GPU Worker Dockerfile
FROM nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu22.04

# Install Python and system dependencies
RUN apt-get update && apt-get install -y \
    python3.10 \
    python3-pip \
    build-essential \
    libopencv-dev \
    libsndfile1 \
    ffmpeg \
    git \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Set Python 3.10 as default
RUN update-alternatives --install /usr/bin/python python /usr/bin/python3.10 1 && \
    update-alternatives --install /usr/bin/pip pip /usr/bin/pip3 1

# Set working directory
WORKDIR /app

# Copy requirements
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Install GPU-specific dependencies
RUN pip install --no-cache-dir \
    torch==2.0.1+cu118 \
    torchvision==0.15.2+cu118 \
    torchaudio==2.0.2+cu118 \
    -f https://download.pytorch.org/whl/torch_stable.html

# Copy application code
COPY autonomous-intelligence/ ./autonomous-intelligence/
COPY engines/ ./engines/
COPY config/ ./config/

# Create necessary directories
RUN mkdir -p /data/jampacked /app/logs /root/.cache

# Set Python path
ENV PYTHONPATH=/app:$PYTHONPATH
ENV CUDA_VISIBLE_DEVICES=0

# Create non-root user (GPU access requires specific setup)
RUN useradd -m -u 1000 -G video jampacked && \
    chown -R jampacked:jampacked /app /data

# Note: Running as root for GPU access, in production use nvidia-container-toolkit
USER root

# Run GPU worker
CMD ["python", "-m", "autonomous-intelligence.workers.gpu_worker"]